"""Tool to generate an obi-one compatible simulation config."""

from typing import ClassVar

from openai import AsyncOpenAI
from pydantic import BaseModel, Field

from neuroagent.tools.autogenerated_types.obione import SimulationsForm
from neuroagent.tools.base_tool import BaseMetadata, BaseTool
from neuroagent.utils import get_token_count


class GenerateSimulationsConfigInput(BaseModel):
    """Inputs of the GenerateSimulationsConfig tool."""

    config_request: str = Field(
        description="A complete description of the desired configuration that will be sent to an LLM for JSON generation. This should describe the ENTIRE configuration as it should exist after any requested changes, not just the modifications. For example, if a user says 'add X to my config' or 'remove Y from my config', translate this into a full description of what the complete configuration should contain, including all existing elements plus the requested additions or minus the requested removals."
    )


class GenerateSimulationsConfigMetadata(BaseMetadata):
    """Metadata of the GenerateSimulationsConfig tool."""

    openai_client: AsyncOpenAI
    token_consumption: dict[str, str | int | None] | None = None


class GenerateSimulationsConfigTool(BaseTool):
    """Class defining the GenerateSimulationsConfig tool."""

    name: ClassVar[str] = "obi-one-generatesimulationsconfig"
    name_frontend: ClassVar[str] = "Generate Simulation Config"
    description: ClassVar[
        str
    ] = """This tool generates JSON configurations for simulations based on natural language descriptions. It takes a user's request for a configuration (including modifications to existing configs) and uses an LLM with structured output to produce the corresponding JSON.
The tool is designed to handle both new configuration requests and modifications to existing configurations. When users request changes like "add feature X" or "remove setting Y", the tool requires a complete description of the desired final configuration state, not just the incremental changes.

Input: A comprehensive description of the desired configuration
Output: Structured JSON configuration generated by an LLM

Use this tool when users need to:
- Create new configurations from scratch
- Modify existing configurations
- Convert configuration requirements into structured JSON format
    """
    description_frontend: ClassVar[
        str
    ] = """Create or modify JSON configurations using natural language.
Simply specify in plain english what you want your configuration to achieve or what changes you'd like to make."""
    metadata: GenerateSimulationsConfigMetadata
    input_schema: GenerateSimulationsConfigInput

    async def arun(self) -> SimulationsForm:
        """Run the tool."""
        system_prompt = """You are a configuration generation specialist for neuroscience simulations. Your task is to convert natural language descriptions of configurations into well-structured JSON format.
        The description of the configuration is going to be the first `user` message you receive.

**Your Role:**
- Take user descriptions of desired configurations and generate corresponding JSON
- Ensure the JSON is valid, properly formatted, and follows best practices
- Make reasonable assumptions for missing details based on common conventions
- Create complete, functional configurations that match the user's intent

**Guidelines:**
1. **JSON Structure**: Always output valid JSON with proper syntax, indentation, and data types
2. **Completeness**: Generate complete configurations, not partial snippets
3. **Best Practices**: Follow standard conventions for the type of configuration being requested
4. **Reasonable Defaults**: When specific values aren't provided, use sensible defaults appropriate for the context or keep the default provided in the output class
5. **Validation**: Ensure all required fields are present and values are appropriate for their intended use

**Output Format:**
Respond ONLY with valid JSON. Do not include explanations, comments, or additional text outside the JSON structure.
"""
        model = "gpt-4o-mini"
        response = await self.metadata.openai_client.beta.chat.completions.parse(
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": self.input_schema.config_request},
            ],
            model=model,
            response_format=SimulationsForm,
        )
        if response.choices[0].message.parsed:
            # Get the output config
            config = response.choices[0].message.parsed

            # Assign token usage
            token_consumption = get_token_count(response.usage)
            self.metadata.token_consumption = {**token_consumption, "model": model}
        else:
            raise ValueError("Couldn't generate a valid simulation config.")
        return config

    @classmethod
    async def is_online(cls) -> bool:
        """Check if the tool is online."""
        return True
